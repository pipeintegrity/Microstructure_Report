---
title: "Microstructure Analysis"
author: "Nathan Switzner and Joel Anderson"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    theme: journal
    number_sections: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)

```

```{r libraries and data}

# load libraries ----------------------------------------------------------
library(janitor)
library(patchwork)
library(tidyverse)
library(readxl)
library(lubridate)
# library(DataCombine)
library(tidymodels)
theme_set(theme_bw(16)) #set theme to save typing
# data import ----------------------------------------
MICRO <- read_excel("Microstructure_Data_Collection_Online_2021_01_05_S5CJ.xlsx",
                    sheet = "Collection2") %>% 
mutate(Sample_Type = str_replace(Sample_Type, "-", "_"),
       name = paste0(Group," ",Feature),
       year = year(Evaluation_Date),
       Path = str_remove(string = Path,pattern = ".jpg"),
       Path = str_remove(string = Path, pattern = ".tif")) 

```

```{r custom plot function}


tp_plot <- function(df, x, y) {
  ggplot(df, aes(x={{x}}, y={{y}})) +
    geom_point(alpha = 0.6,
               col = 'midnightblue',
               size = 2) +
    geom_abline(col = 'grey50', 
                lty = 3, 
                lwd = 1.2) +
    tune::coord_obs_pred() +
    geom_smooth(method = "lm", se=F)+
    theme_bw(16, "serif")
}

```

This report is automatically generated based on the data collection file produced by Pacific Gas and Electric (PG&E) Facilities Integrity Management Program (FIMP) microstructural analysis team. The microstructural analysis team regularly performs two types of analysis for microstructures: grain size and percent dark phase (pearlite) estimation. These two types of analysis are important inputs to strength, grade, and vintage estimation procedures. Two methods are used for each analysis: counting and comparison methods. The counting and comparison methods for grain size are based on the ASTM E112 Jeffries planimetric method and comparison method, respectively. The counting method for dark phase is based on ASTM E562, and the comparison method for dark phase estimation was developed by PG&E.

# MLI GS and DP summary table

For each pipe or fitting (Feature) from the ATS-ARBH and Modesto groups, the following table identifies the number of evaluations that have been performed (Count) and the the median, mean, and standard deviation (StDev).

The purpose of this table is to review the data for the features that have already been evaluated and identify the features that require more evaluations. Some features may be missing from the list entirely, and should be assigned for evaluation.

```{r}
MICROTABLE_MLI <-  MICRO %>%
  filter(Skip == "NoSkip") %>% 
  filter(Analysis_Type == "Grain_Size") %>%
  group_by(name, Sample_Type) %>%
  summarize(
    MLI_Count = n(),
    MLI_Median = round(median(Mean_Linear_Intercept, na.rm = T), 1),
    MLI_Mean = round(mean(Mean_Linear_Intercept, na.rm = T), 1),
    MLI_StDev = round(sd(Mean_Linear_Intercept, na.rm = T), 1))

# DT::datatable(MICROTABLE_MLI,filter="top",
#              caption = "Mean linear intercept (MLI) (μm) Summary Table")
```
## Count of Evaluations by File Name  
```{r filnema_count}
MICRO %>% 
  group_by(Path) %>% 
  summarise(n=n()) %>% 
  arrange(n) %>% 
  DT::datatable(filter = "top", 
                caption = "Number of Evaluations by Filename")

```



```{r TableDP1}

MICROTABLE_DP = MICRO %>% 
  filter(Skip == "NoSkip") %>% 
  filter(Analysis_Type == "Dark_Phase") %>% 
  group_by(name,Sample_Type) %>% 
            summarize(
            DP_Count = n(),
            DP_Median = round(median(Pct_Dark_Phase,na.rm=T),1),
            DP_Mean = round(mean(Pct_Dark_Phase,na.rm=T),1),
            DP_StDev = round(sd(Pct_Dark_Phase,na.rm = T),1))

# DT::datatable(MICROTABLE_DP,filter="top",
#              caption = "Percent dark phase summary table")
```

```{r}
MICROTABLE <- left_join(MICROTABLE_MLI,MICROTABLE_DP,
          by = c("name", "Sample_Type"))

DT::datatable(MICROTABLE,filter="top",
              caption = "Percent dark phase summary table")
```

# Data for mean linear intercept (MLI) grain size (GS)

There are two dimensions used frequently for describing grain size, ASTM grain size (GS) and mean linear intercept (MLI) GS. MLI GS will be used in this report because it relates to an actual physical dimension in the microstructure (mean distance between grain intersections for random lines drawn on the microstructure) and is reported herein in units of micrometers (μm). The ASTM GS sometimes enables better comparison of the standard deviation from large grain sizes to small grain sizes. Thus we will provide here the formulae to convert between MLI and ASTM GS as desired.

ASTM E112 defines grain size number, G as $N_{AE}=2^{G-1}$ where $N_{AE}$ is the number of grains per square inch at 100X magnification. To obtain the number per square millimeter at 1X, multiply by 15.50. For relating ASTM grain size number, G, to mean linear intercept, L, ASTM E112 defines G such that G=0 when L=320 μm. Thus, $G=10-2*LOG_2(L/10)$ and $L=320*2^{-G/2}$ for L in micrometers (μm).

The data identified as erroneous (selected to "skip") through the quality control (QC) process has been eliminated from this section.  

## Evaluator Metrics  

```{r monthly metrics plot, fig.width = 8}

MICRO %>%
  filter(year(Evaluation_Date) == year(Sys.Date()) - 1) %>%
  # mutate(month = month.abb(month(Evaluation_Date))) %>%
  group_by(eval = Evaluator_LANID,
           month_num = month(Evaluation_Date)) %>%
  summarise(n = n()) %>%
  mutate(cumusum = cumsum(n), 
         month = month.abb[month_num],
         month = factor(month, levels = month.abb)) %>%
  ggplot(aes(month_num, cumusum, col = eval)) +
  geom_step(lwd = 1.2) +
  theme_bw(16, "serif") +
  scale_x_continuous(breaks = 1:12) +
  scale_color_viridis_d(option = "C") +
  labs(
    title = paste("Cummulative Evaluations by ID for", year(Sys.Date()) - 1),
    x = "Month",
    y = "Cummulative Count",
    color="Evaluator"
  )
  

MICRO %>%
  filter(year == 2021) %>%
  # mutate(month = month.abb(month(Evaluation_Date))) %>%
  group_by(eval = Evaluator_LANID,
           month = month(Evaluation_Date)) %>%
  summarise(n = n()) %>%
  mutate(cumusum = cumsum(n)) %>%
  ggplot(aes(month, cumusum)) +
  geom_step(lwd = 1.2, aes(col = eval), position = "dodge") +
  theme_bw(16, "serif") +
  scale_x_continuous(breaks = 1:12) +
  scale_color_viridis_d(option = "C") +
  labs(
    title = paste("Cummulative Evaluations by ID for", year(Sys.Date())),
    x = "Month",
    y = "Cummulative Count",
    color="Evaluator"
  )

```


## Evaluator Metrics Table 
This table can be sorted by any field by clicking on the arrows at the column head.

```{r eval_table}

MICRO %>%
  group_by(
    ID = Evaluator_LANID,
    year = year(Evaluation_Date),
    month_num = month(Evaluation_Date)
  ) %>%
  filter(year == year(Sys.Date())) %>%
  # factor(month, levels = month.abb))
  summarise(n = n()) %>%
  mutate(#cummulative = cumsum(n),
    month = month.abb[month_num],
    month = factor(month, levels = month.abb)) %>%
  arrange(month) %>%
  relocate(month, .before = n) %>%
  pivot_wider(
    names_from = month,
    values_from = n,
    id_cols = ID,
    values_fn = sum
  ) %>%
  mutate(Total = sum(c_across(cols = everything()),
                     na.rm = T)) %>%
  # select(-month_num) %>%
  DT::datatable()
```

## MLI GS for cross-sections

This plot enables visualization of the data distribution. Interestingly, for grain sizes less than \~5 μm it appears that evaluators chose to rely the comparison method and avoid the counting methods.

```{r GS9, fig.height=12, fig.width=6.5, fig.align='center', fig.cap = "ASTM GS evaluated for destructive cross-sections by the counting method."}

MICRO %>%
  # mutate(number = as.numeric(str_remove(Feature,"Feature "))) %>%
  # reorder(nnumber) %>%
  # arrange(number) %>%
  filter(Skip == "NoSkip",
         Sample_Type == "Cross_section",
         Analysis_Type == "Grain_Size") %>%
  # select(name,
  #        # number,
  #        Mean_Linear_Intercept) %>%
  # na.omit() %>%
  ggplot() +
  geom_boxplot(aes(x = name, 
                   y = Mean_Linear_Intercept, 
                   fill = Method),
               alpha = 0.75) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 25)) +
  # scale_x_discrete(limits = name) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = expression("Mean linear intercept GS (" ~ mu ~ "m)")) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = c(0.8, 0.075))

```

```{r GS10, fig.height=9, fig.width=6.5, fig.align='center', fig.cap= "ASTM GS evaluated for destructive cross-sections by the comparison method."}

# MICRO %>%
#   filter(Skip == "NoSkip") %>%
#   filter(Analysis_Type == "Grain_Size") %>% 
#   filter(Sample_Type == "Cross_section" &
#            Method == "Comparison") %>%
#   ggplot() +
#   geom_boxplot(aes(x = name, y = Mean_Linear_Intercept),
#                fill = "steelblue2",
#                alpha = 0.75) +
#   coord_flip()+
#   scale_y_continuous(limits = c(0, 25)) +
#   theme_bw() +
#   labs(x = "Pipe or Fitting",
#        y = expression("Mean linear intercept GS (" ~ mu ~ "m)")) +
#   theme(axis.text.x = element_text(angle = 90))

```

## MLI GS for cross-sections (ascending order)

The purpose of these plots is qualitative identification and comparison of the features with small and large grains between the two analysis methods.

```{r GS11, fig.height=12, fig.width=6.5, fig.align='center', fig.cap= "ASTM GS evaluated for destructive cross-sections by the counting method (ascending sort)."}

MICRO %>%
  filter(Skip == "NoSkip",
         Analysis_Type == "Grain_Size",
         Sample_Type == "Cross_section") %>%
  mutate(name = fct_reorder(name,
                            Mean_Linear_Intercept,
                            .fun = 'mean')) %>%
  ggplot() +
  geom_boxplot(aes(x = name,
                   y = Mean_Linear_Intercept, fill = Method),
               alpha = 0.75) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 25)) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = expression("Mean Linear Intercept GS (" ~ mu ~ "m)")) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = c(0.8, 0.1))

```

```{r GS12, fig.height=9, fig.width=6, fig.align='center', fig.cap= "ASTM GS evaluated for destructive cross-sections by the comparison method (ascending sort)"}

# MICRO %>%
#   filter(
#     Skip == "NoSkip",
#     Analysis_Type == "Grain_Size",
#     Sample_Type == "Cross_section",
#     Method == "Comparison"
#   ) %>%
#   mutate(name = fct_reorder(name,
#                             Mean_Linear_Intercept,
#                             .fun = 'mean')) %>%
#   ggplot() +
#   geom_boxplot(aes(x = name,
#                    y = Mean_Linear_Intercept),
#                fill = "steelblue2",
#                alpha = 0.75) +
#   coord_flip() +
#   scale_y_continuous(limits = c(0, 25)) +
#   theme_bw() +
#   labs(x = "Pipe or Fitting",
#        y = expression("Mean linear intercept GS (" ~ mu ~ "m)")) +
#   theme(axis.text.x = element_text(angle = 90))

```

## MLI GS for Replicas

The purpose of these plots is visualization of the data distribution. It is interesting to note that for grain sizes less than \~5 μm it appears that evaluators opted to use the comparison method only and avoid using the counting methods.

```{r GS13, fig.height=12, fig.width=6, fig.align='center', fig.cap="ASTM GS evaluated for microstructural replicas by the counting method."}

MICRO %>%
  filter(Skip == "NoSkip",
         Analysis_Type == "Grain_Size",
         Sample_Type == "Replica") %>%
  ggplot() +
  geom_boxplot(aes(x = name,
                   y = Mean_Linear_Intercept,
                   fill = Method),
               alpha = 0.75) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 25)) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = expression("Mean linear intercept GS (" ~ mu ~ "m)")) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = c(0.8, 0.05))

```

```{r GS14, fig.height=9, fig.width=6, fig.align='center', fig.cap="ASTM GS evaluated for microstructural replicas by the comparison method."}
# 
# MICRO %>%
#   filter(Skip == "NoSkip") %>%
#   filter(Analysis_Type == "Grain_Size") %>% 
#   filter(Sample_Type == "Replica" & Method == "Comparison") %>%
#   
#   ggplot() +
#   geom_boxplot(aes(x = name,
#                    y = Mean_Linear_Intercept),
#                fill = "steelblue2",
#                alpha = 0.75) +
#   coord_flip()+
#   scale_y_continuous(limits = c(0, 25)) +
#   theme_bw() +
#   labs(x = "Pipe or Fitting",
#        y = expression("Mean linear intercept GS (" ~ mu ~ "m)")) +
#   theme(axis.text.x = element_text(angle = 90))


```

## MLI GS for Replicas (ascending order)

The purpose of these plots is qualitative identification and comparison of the features with small and large grains between the two analysis methods.

```{r GS15, fig.height=12, fig.width=6.5, fig.align='center', fig.cap="ASTM GS evaluated for microstructural replicas (ascending sort)"}

MICRO %>%
  filter(Skip == "NoSkip",
         Analysis_Type == "Grain_Size",
         Sample_Type == "Replica") %>%
  
  mutate(name = fct_reorder(name, Mean_Linear_Intercept, .fun = 'mean')) %>%
  ggplot() +
  geom_boxplot(
    aes(x = name,
        y = Mean_Linear_Intercept,
        fill = Method),
    alpha = 0.75
  ) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 25)) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = expression("Mean linear intercept GS (" ~ mu ~ "m)")) +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = c(0.8, 0.1))

```

```{r GS16, fig.height=9, fig.width=6, fig.align='center', fig.cap="ASTM GS evaluated for microstructural replicas by the comparison method (ascending sort)."}

# MICRO %>%
#   filter(Skip == "NoSkip") %>%
#   filter(Analysis_Type == "Grain_Size") %>%
#   filter(Sample_Type == "Replica" & Method == "Comparison") %>%
#   
#   mutate(name = fct_reorder(name, Mean_Linear_Intercept, .fun = 'mean')) %>%
#   ggplot() +
#   geom_boxplot(
#     mapping = aes(x = name,
#                   y = Mean_Linear_Intercept),
#     fill = "steelblue2",
#     alpha = 0.75
#   ) +
#   coord_flip() +
#   scale_y_continuous(limits = c(0, 25)) +
#   theme_bw() +
#   labs(x = "Pipe or Fitting",
#        y = expression("Mean linear intercept GS (" ~ mu ~ "m)")) +
#   theme(axis.text.x = element_text(angle = 90))

```

# Data for dark phase (DP)

The data identified as erroneous (selected to "skip") through the quality control (QC) process has been eliminated from this section.

## DP for cross-sections

The purpose of these plots is visualization of the data distribution.

```{r DP1, fig.height=12, fig.width=6.5, fig.align='center', fig.cap="DP (%) evaluated for destructive cross-sections"}

MICRO %>%
  filter(Skip == "NoSkip",
  Analysis_Type == "Dark_Phase",
  Sample_Type == "Cross_section") %>%
  ggplot() +
  geom_boxplot(aes(x = name,
                   y = Pct_Dark_Phase,
                   fill=Method),
               alpha = 0.75) +
  coord_flip()+
  scale_y_continuous(limits = c(0, 60)) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = "Dark Phase (%)") +
  theme(axis.text.x = element_text(angle = 90), 
        legend.position = c(0.8, 0.1))

```

```{r DP2, fig.height=9, fig.width=6, fig.align='center', fig.cap="DP (%) evaluated for destructive cross-sections by the comparison method."}

# MICRO %>%
#   filter(Skip == "NoSkip") %>%
#   filter(Analysis_Type == "Dark_Phase") %>%
#   filter(Sample_Type == "Cross_section" &
#            Method == "Comparison") %>%
#   ggplot() +
#   geom_boxplot(aes(x = name,
#                    y = Pct_Dark_Phase),
#                fill = "steelblue2",
#                alpha = 0.75) +
#   coord_flip()+
#   scale_y_continuous(limits = c(0, 60)) +
#   theme_bw() +
#   labs(x = "Pipe or Fitting",
#        y = "Dark Phase (%)") +
#   theme(axis.text.x = element_text(angle = 90))

```

## DP for cross-sections (ascending order)

The purpose of these plots is qualitative identification and comparison of the features with a small or large amount of dark phase between the two analysis methods.

```{r DP3, fig.height=12, fig.width=6.5, fig.align='center', fig.cap= "DP (%) evaluated for destructive cross-sections (ascending sort)"}


MICRO %>%
  filter(Skip == "NoSkip",
         Analysis_Type == "Dark_Phase",
         Sample_Type == "Cross_section") %>%
  mutate(name = fct_reorder(name,
                            Pct_Dark_Phase,
                            .fun = 'mean')) %>%
  ggplot() +
  geom_boxplot(mapping = aes(x = name,
                             y = Pct_Dark_Phase,
                             fill = Method),
               alpha = 0.75) +
  coord_flip() +
  # scale_y_continuous(limits = c(0, 60)) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = "Dark phase (%)") +
  theme(axis.text.x = element_text(angle = 90), 
        legend.position = c(0.8, 0.1))

```

```{r DP4, fig.height=9, fig.width=6, fig.align='center', fig.cap= "DP (%) evaluated for destructive cross-sections by the comparison method (ascending sort)."}
# 
# MICRO %>%
#   filter(Skip == "NoSkip") %>%
#   filter(Analysis_Type == "Dark_Phase") %>%
#   filter(Sample_Type == "Cross_section",
#          Method == "Comparison") %>%
#   
#   mutate(name = fct_reorder(name,
#                                Pct_Dark_Phase,
#                                .fun = 'mean')) %>%
#   ggplot() +
#   geom_boxplot(aes(x = name,
#                    y = Pct_Dark_Phase),
#                fill = "steelblue2",
#                alpha = 0.75) +
#   coord_flip()+
#   scale_y_continuous(limits = c(0, 60)) +
#   theme_bw() +
#   labs(x = "Pipe or Fitting",
#        y = "Dark phase (%)") +
#   theme(axis.text.x = element_text(angle = 90))

```

## DP for Replicas

The purpose of these plots is visualization of the data distribution.

```{r DP5, fig.height=12, fig.width=6.5, fig.align='center', fig.cap="DP (%) evaluated for replicas"}

MICRO %>%
  filter(Skip == "NoSkip",
         Analysis_Type == "Dark_Phase",
         Sample_Type == "Replica") %>%
  
  ggplot() +
  geom_boxplot(aes(x = name,
                   y = Pct_Dark_Phase,
                   fill = Method),
               alpha = 0.75) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 60)) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = "Dark Phase (%)") +
  theme(axis.text.x = element_text(angle = 90), 
        legend.position = c(0.8, 0.1))

```

```{r DP6, fig.height=9, fig.width=6, fig.align='center', fig.cap="DP (%) evaluated for replicas by the comparison method."}

# MICRO %>%
#   filter(Skip == "NoSkip") %>%
#   filter(Analysis_Type == "Dark_Phase") %>%
#   filter(Sample_Type == "Replica",
#          Method == "Comparison") %>%
#   
#   ggplot() +
#   geom_boxplot(aes(x = name,
#                    y = Pct_Dark_Phase),
#                fill = "steelblue2",
#                alpha = 0.75) +
#   coord_flip()+
#   scale_y_continuous(limits = c(0, 60)) +
#   theme_bw() +
#   labs(x = "Pipe or Fitting",
#        y = "Dark Phase (%)") +
#   theme(axis.text.x = element_text(angle = 90))

```

## DP for replicas (ascending order)

The purpose of these plots is qualitative identification and comparison of the features with a small or large amount of dark phase between the two analysis methods.

```{r DP7, fig.height=12, fig.width=6.5, fig.align='center', fig.cap= "DP (%) evaluated for replicas (ascending sort)"}

MICRO %>%
  filter(Skip == "NoSkip",
         Analysis_Type == "Dark_Phase",
         Sample_Type == "Replica") %>%
  mutate(name = fct_reorder(name,
                            Pct_Dark_Phase,
                            .fun = 'mean')) %>%
  ggplot() +
  geom_boxplot(
    mapping = aes(x = name,
                  y = Pct_Dark_Phase,
                  fill = Method),
    alpha = 0.75
  ) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 60)) +
  theme_bw() +
  labs(x = "Pipe or Fitting",
       y = "Dark phase (%)") +
  theme(axis.text.x = element_text(angle = 90), 
        legend.position = c(0.8, 0.1))

```

```{r DP8, fig.height=9, fig.width=6, fig.align='center', fig.cap= "DP (%) evaluated for replicas by the comparison method (ascending sort)."}

# MICRO %>%
#   filter(Skip == "NoSkip") %>%
#   filter(Analysis_Type == "Dark_Phase") %>%
#   filter(Sample_Type == "Replica",
#          Method == "Comparison") %>%
#   mutate(name = fct_reorder(name,
#                                Pct_Dark_Phase,
#                                .fun = 'mean')) %>%
#   ggplot() +
#   geom_boxplot(aes(x = name,
#                    y = Pct_Dark_Phase),
#                fill = "steelblue2",
#                alpha = 0.75) +
#   coord_flip()+
#   scale_y_continuous(limits = c(0, 60)) +
#   theme_bw() +
#   labs(title = "",
#        x = "Pipe or Fitting",
#        y = "Dark phase (%)") +
#   theme(axis.text.x = element_text(angle = 90))

     
```

# Method validation: comparison vs counting

Since we are using both comparison methods and counting methods, it is important to validate that the two methods provide similar results.

## MLI GS

```{r compare 1}

compare1 <- MICRO %>%
  group_by(name, Method) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting,
             Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
 labs(title = "Comparison vs counting for MLI GS (\u03BCm)", 
       subtitle =  "Skips Included")+
  coord_obs_pred()+
  theme_bw(10, "calibri")

```

```{r compare 2}

compare2 <- MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Method) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting, Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Comparison vs counting for MLI GS (\u03BCm)", 
       subtitle =  "Skips Excluded")+
  coord_obs_pred()+
    theme_bw(10, "calibri")

compare1 + compare2

```

  
```{r fig.width = 8, fig.align = 'center', fig.cap= "Comparison vs counting for MLI GS (\u03BCm) by evaluator (skips included)"}

MICRO %>%
  group_by(name, Method, Evaluator_LANID) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting, Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = .5,
              lty = 3,
              col = 'black') +
  facet_wrap(~ Evaluator_LANID) +
  coord_obs_pred()+
  theme(plot.margin = margin(0.5,0.5,0.5,0.5,"cm"))




```
  
```{r  fig.width = 8, fig.align = 'center', fig.cap= "Comparison vs counting for MLI GS (\u03BCm) by evaluator (skips excluded)"}

MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Method, Evaluator_LANID) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting, Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = .5,
              lty = 3,
              col = 'black') +
  facet_wrap(~ Evaluator_LANID) +
  coord_obs_pred()+
  theme(plot.margin = margin(0.5,0.5,0.5,0.5,"cm"))

```

## Dark Phase

The comparison method for dark phase is a method developed by PG&E, therefore is validated here vs the ASTM E562 counting method.
  
```{r compare3}

compare3 <- MICRO %>%
  group_by(name, Method) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting, Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Comparison vs Counting for DP (%)", 
       subtitle = "Skips Included")+
  coord_obs_pred()

```
  
```{r compare4}

compare4 <- MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Method) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting, Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Comparison vs Counting for DP (%)", 
       subtitle = "Skips Excluded")+
  coord_obs_pred()

  compare3 + compare4
  
```
  
```{r fig.width=6.5,  fig.align='center', fig.cap= "Comparison vs counting for DP by evaluator (skips included)."}

MICRO %>%
  group_by(name, Sample_Type, Method, Evaluator_LANID) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting, Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = .5,
              lty = 3,
              col = 'black') +
  facet_wrap(~ Evaluator_LANID) +
  coord_obs_pred()+
  theme(plot.margin = margin(0.5,0.5,0.5,0.5,"cm"))

```
  
```{r fig.width=6.5,  fig.align='center', fig.cap= "Comparison vs counting for DP by evaluator (skips excluded)."}

MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Sample_Type, Method, Evaluator_LANID) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Method, values_from = avg) %>%
  ggplot(aes(Counting, Comparison)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "counting",
       y = "comparison") +
  theme_bw() +
  geom_abline(lwd = .5,
              lty = 3,
              col = 'black') +
  facet_wrap(~ Evaluator_LANID) +
  coord_obs_pred()

```

# Sample type validation: cross-section vs replica

Since we are targeting the use of non-destructive methods for integrity management purposes, it is important to validate that the data from evaulations using replicas of the surface microstructure are similar to the data from evaluations using laboratory cross-sections of the pipes.

## MLI GS

```{r compare5}

compare5 <- MICRO %>%
  group_by(name, Sample_Type) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(Replica, Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle =  "for MLI GS (\u03BCm) (Skips Included)") +
  coord_obs_pred()

```
  
```{r compare6}

compare6 <- MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Sample_Type) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(Replica, Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle =  "for MLI GS (\u03BCm) (Skips Excluded)") +
  coord_obs_pred()

compare5 + compare6

```
  
```{r compare7}

compare7 <- MICRO %>%
  group_by(name, Sample_Type, Method) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(col = Method, Replica, Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = T) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle =  "for MLI GS (\u03BCm) (Skips Included)") +
  coord_obs_pred() +
  theme(legend.position = "bottom")

```
  
```{r compare8}

compare8 <- MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Sample_Type, Method) %>%
  summarize(avg = mean(Mean_Linear_Intercept, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(col = Method, Replica, Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = T) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle =  "for MLI GS (\u03BCm) (Skips Excluded)") +
  coord_obs_pred() +
  theme(legend.position = "bottom")

compare7 + compare8

```
  
## DP

```{r compare9 }

compare9 <- MICRO %>%
  group_by(name, Sample_Type) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(Replica, Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle =  "for DP (Skips Included)")+
coord_obs_pred()

```
  
```{r compare10}

compare10 <- MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Sample_Type) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(Replica, Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = F) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle =  "for DP (Skips Excluded)") +
  coord_obs_pred()

compare9 + compare10

```
  
```{r compare11}

compare11 <- MICRO %>%
  group_by(name, Sample_Type, Method) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(col = Method,
             Replica,
             Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = T) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle = "for DP (Skips Included)")+
coord_obs_pred() +
  theme(legend.position = "bottom")

```
  
```{r compare12}

compare12 <- MICRO %>%
  filter(Skip == "NoSkip") %>%
  group_by(name, Sample_Type, Method) %>%
  summarize(avg = mean(Pct_Dark_Phase, na.rm = T)) %>%
  pivot_wider(names_from = Sample_Type, values_from = avg) %>%
  ggplot(aes(col = Method,
             Replica,
             Cross_section)) +
  geom_point(alpha = 0.5,
             show.legend = T) +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Replica",
       y = "Cross-Section") +
  theme_bw() +
  geom_abline(lwd = 0.5,
              lty = 3,
              col = 'black') +
  labs(title = "Destructive Cross-Section vs Replica",
       subtitle = "for DP (Skips Excluded)") +
  coord_obs_pred() +
  theme(legend.position = "bottom")

compare11 + compare12

```
  
# Quality control skips and reasons

The purpose of this table is for evaluators to identify their common errors and self correct.

```{r skiptable}

SKIPTABLE = MICRO %>%
  filter(Skip == "Skip") %>%
  select(
    Evaluator_LANID,
    Evaluation_Date,
    Path,
    Method,
    Pct_Dark_Phase,
    Mean_Linear_Intercept,
    Skip_Reason
  ) %>%
  rename(
    Evaluator = Evaluator_LANID,
    Date = Evaluation_Date,
    DP_pct = Pct_Dark_Phase,
    MLI_GS = Mean_Linear_Intercept
  ) %>%
  mutate(MLI_GS = round(MLI_GS, 1),
         Date = ymd(Date)) %>%
  arrange(Evaluator,
          Date)

DT::datatable(SKIPTABLE, filter = "top",
              caption = "List of evaluation errors selected to skip")
```


## Correlations  
```{r ECA info,warning=FALSE}
comp <-
  read_excel("~/RSI/ChemistryGrade/MasterDB-SQL-2020-09-24.xlsx",
             sheet = "Composition") %>%
  janitor::clean_names() %>%
  filter(skip==FALSE) %>%
  select(group, feature, c:p) %>%
  group_by(group, feature) %>%
  mutate(across(.cols = c:p, as.numeric)) %>%
  summarise(across(.cols = c:p, ~mean(.x, na.rm=T)))


# IIT data ----------------------------------------------------------------

ndt <-
 read_excel("~/RSI/ChemistryGrade/MasterDB-SQL-2020-09-24.xlsx",
             sheet = "NDT") %>%
  janitor::clean_names() %>%
  rename(group = group_name) %>%
  filter(
    skip == FALSE,
    group != "Calibration Blocks",
    str_detect(
      "Old",
      negate = T,
      vendor_test_area_label),
      reader_method == "DPT",
      vendor %in% c('ATS', 'TDW')
    ) %>%
      group_by(group, feature) %>%
      summarise(
        iitys_5 = mean(x0_5_percent_eul_ys_ksi, na.rm = T),
        iituts = mean(uts_ksi, na.rm = T),
        nsamples = n()
      ) %>%
      filter(nsamples >= 10
      )


# Tensile data ------------------------------------------------------------


tensile <-
read_excel("~/RSI/ChemistryGrade/MasterDB-SQL-2020-09-24.xlsx",
             sheet = "Tensile") %>%
  janitor::clean_names() %>%
  filter(skip == FALSE ,
         type != "Weld" ,
         type != "GirthWeldStrip" ,
         group != "Calibration Blocks") %>%
  rename(ys5 = x0_5_percent_eul_ys_ksi,
         uts = uts_ksi) %>%
  group_by(group, feature) %>%
  summarise(ten_ys = mean(ys5, na.rm = T),
            ten_uts = mean(uts, na.rm = T))

## Charpy data ----------------------------------------------------------

ECA_WT <- read_excel("~/RSI/ChemistryGrade/MasterDB-SQL-2020-09-24.xlsx",
                     sheet = "Wall Thickness")  %>%
  clean_names() %>%
  filter(str_detect(location_type, "AFG", negate = T)) %>%  #remove any wall thickness measurements after grind
  group_by(group, feature) %>%
  summarize(wt_in = mean(measurement_in, na.rm = T)) %>%
  select(group,
         feature,
         wt_in)

ECA_CVN <- read_excel("~/RSI/ChemistryGrade/MasterDB-SQL-2020-09-24.xlsx",
                         sheet = "Charpy")  %>%
  clean_names() %>% 
  full_join(ECA_WT, by= c("group", "feature")) %>% 
  filter(str_detect(location, "Base")) %>% #removing weld tests
  mutate(
    SA_SS = ifelse(shear_area_percent==100, 0.99,shear_area_percent/ 100),
    t_ss_in = charpy_size_mm / 25.4,
    #calc subsize charpy thickness in inches
    sigB = (-12.736) * (t_ss_in / .394) ^ 2 +
      39.984 * (t_ss_in / 0.394) + 4.6897,
    #calc sigmoidal parameter B
    sigA = (-21.812) * (t_ss_in / 0.394) ^ 2 + 68.279 * (t_ss_in / 0.394) +
      8.4349,
    #calc sigmoidal parameter A
    TT_SS_F =  (temperature_f - sigB * log(SA_SS /
                                          (1 - SA_SS)) + sigA) * 0.95 ,
    TT_FS_F = TT_SS_F + 66 * (wt_in ^ 0.55) *
      (t_ss_in ^ (-.7) - 0.394 ^ (-.7)),
    
    CVN_SS = absorbed_energy_ft_lbs,
    #rename subsize CVN
    
    #calc subsize shear area and rename
    CVN_US_SS = CVN_SS / (0.9 * SA_SS + 0.1),
    #calc subsize CVN upper shelf energy from subsize CVN and subsize shear area
    CVN_US_FS = CVN_US_SS * 0.394 / t_ss_in
    #calc fullsize CVN upper shelf energy
  ) %>%
  group_by(group, feature) %>%
  summarize(
    CVN_US_FS = mean(CVN_US_FS, na.rm = T),
    TT_FS_F = mean(TT_FS_F, na.rm = T)
  ) %>%
  select("group", "feature", "CVN_US_FS", "TT_FS_F")
#-------------------------------------------------------------------------
micro <- MICRO %>%
  rename(group = Group,
         feature = Feature,
         polygonal =`Polygonal ferrite grains that are relatively distinct and free of dots, lines or cloudy features.`) %>% 
  janitor::clean_names() %>% 
  group_by(group, feature, method) %>% 
  select(astm_grain_size, mean_linear_intercept,pct_dark_phase) %>% 
  summarise(astm_grain_size=mean(astm_grain_size, na.rm=T),
         mean_linear_intercept = mean(mean_linear_intercept, na.rm=T),
         pct_dark_phase = mean(pct_dark_phase, na.rm=T)
         ) %>% 
  ungroup()

## Coombine the data -----------------------------------------------------
ndt_ten_comp <- ndt %>%
  full_join(comp,
            by = c("group", "feature")) %>%
  full_join(tensile,
            by = c("group", "feature")) %>%
  full_join(ECA_CVN, 
            by = c("group", "feature")) %>% 
  full_join(micro, 
            by = c("group", "feature")) %>% 
  ungroup()
```

## MLI plots  
```{r mli plots}

lm_model <-
  linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

complete <- ndt_ten_comp %>%
  select(CVN_US_FS,
         ten_ys,
         iitys_5,
         c,
         mn,
         s,
         si,
         p,
         mean_linear_intercept,
         astm_grain_size,
         pct_dark_phase,
         method) %>%
  mutate(sr_mli=sqrt(mean_linear_intercept)) %>% 
  rename(ags = astm_grain_size,
         pdp = pct_dark_phase,
         mli = mean_linear_intercept) %>%
  drop_na() 


ys_rec <-
  recipe(ten_ys ~ iitys_5+ c + mn + s + si + p + ags + pdp + mli,
         data = complete) %>%
  step_center(all_predictors()) %>%
  # step_scale(all_predictors()) %>%
  step_interact(terms = ~ c(mn:c, ags:pdp, c:si)) %>%
  prep() #retain data =TRUE is default

ys_bake <- bake(ys_rec, new_data = NULL)

# fit the model
fitted_m <-  fit(lm_model,
                 formula = ten_ys ~ iitys_5 + mn * c + ags ,
                 data = ys_bake)


fitted_mnc <- fit(lm_model,
                  formula = ten_ys ~ iitys_5 + si + ags ,
                  data = ys_bake)

glance(fitted_mnc)
summary(fitted_mnc$fit)

glance(fitted_m)
# fitted_iit$fit# fitted model object

#extract coefficients
tidy_iit <- tidy(fitted_mnc, conf.int=T) %>% 
  mutate(model ="IIT") 

#extract performance metrics
# iit_glance <- glance(fitted_iit$fit) %>%
#   mutate(model ="IIT") %>% 
#   relocate(model)

#attach the preidcted values to the original data
ys_aug <- augment(fitted_mnc$fit,interval = "prediction") %>%
  mutate(model="IIT")


```
 
```{r iit-regress, fig.cap="Regression Results"}
# ys_aug %>%
#   # pivot_longer(cols = c(.fitted_iit, .fitted_comp)) %>%
#   ggplot(aes(y = ten_ys, x = .fitted)) +
#   geom_jitter(width = 0.1, 
#               height = 0.1,
#               alpha = 0.65, 
#               col = 'midnightblue') +
#   coord_obs_pred() +
#   geom_abline(lty = 2, col = 'grey50') +
#   geom_smooth(method = "lm", se = T, col='orange') +
#   scale_color_brewer(type = "div", palette = "Set1") +
#   labs(title = "IIT Only Model Observed vs. Predicted",
#        x = "Predicted Tensile (ksi)",
#        y = "Observed Tensile (ksi)",caption = "ys ~ mn + c+ iit + grain_size")

```

```{r cvn_vs_mli}

ndt_ten_comp %>% 
  ggplot(aes(sqrt(mean_linear_intercept),CVN_US_FS))+
  geom_point()+
  geom_smooth(method = "lm", se=F)

cvn_rec <-
  recipe(CVN_US_FS ~ iitys_5+ c + mn + s + si + p + ags + pdp + mli,
         data = complete) %>%
  step_center(all_predictors()) %>%
  # step_scale(all_predictors()) %>%
  step_interact(terms = ~ c(mn:c, ags:pdp, c:si, c:s, ags:mli)) %>%
  prep() #retain data =TRUE is default

cvn_bake <- bake(cvn_rec, new_data = NULL)


mli_lm <- lm(CVN_US_FS ~ mli, data = cvn_bake)

mli_lm2 <- update(mli_lm, . ~ . + iitys_5)# no good
mli_lm3 <- update(mli_lm, . ~ . + ags:mli) # significant
mli_lm4 <- update(mli_lm, . ~ . + pdp*ags + c) # no good
mli_lm5 <- update(mli_lm, . ~ . + pdp*ags + s)

models <-list(mli_lm, mli_lm2, mli_lm3, mli_lm4, mli_lm5)

mli_lm6 <- complete %>% 
  select(CVN_US_FS, pdp, ags, c,s, mli, method) %>% 
  nest(c(-method)) %>% 
  mutate(fit = map(data, ~lm(CVN_US_FS ~ sqrt(mli)+pdp/ags + c:s, data = .x)),
         glanced = map(fit, glance),
         tidied = map(fit, tidy)
         )
tidy_pre

modelsummary::modelsummary(models)

mli_lm6 %>% 
  select(glanced) %>% 
  unnest(glanced) %>% 
  mutate(method=c("Comparison", "Counting")) %>% 
  relocate(method) %>% 
  select(method:sigma,-p.value, deviance) %>% 
  mutate(across(.cols = c(2:5), ~ round(.x,2))) %>% 
  flextable::flextable()

```

```{r plots of cvn model}
mli_aug <- augment(mli_lm4, newdata=cvn_bake) %>% mutate(method = complete$method)
mli_aug2 <- augment(mli_lm5, newdata=cvn_bake) %>% mutate(method = complete$method)

sulfur <- mli_aug2 %>% 
  ggplot(aes(.fitted,CVN_US_FS))+
  geom_point(aes(col=method), alpha=0.5)+
  geom_abline(lty=2, col='grey50')+
  coord_obs_pred()+
  scale_color_brewer(type = "div",palette = "Set1")+
   labs(title = "Observed CVN vs. Predicted",
       x="Predicted CVN (ft-lb)",
       y = "Full-Size US CVN (ft-lb)",
       caption = "Model: CVN ~ MLI + AGS:DP + S",
       color="Method")

carbon <- mli_aug %>% 
  ggplot(aes(.fitted,CVN_US_FS))+
  geom_point(aes(col=method), alpha=0.5)+
  geom_abline(lty=2, col='grey50')+
  coord_obs_pred()+
  scale_color_brewer(type = "div",palette = "Set1")+
   labs(title = "Observed CVN vs. Predicted",
       x="Predicted CVN (ft-lb)",
       y = "Full-Size US CVN (ft-lb)",
       caption = "Model: CVN ~ MLI + AGS:DP + C",
       color="Method")

library(patchwork)

sulfur + carbon
```



```{r grain_size}

gs_lm <- lm(CVN_US_FS ~ astm_grain_size,data = ndt_ten_comp) #signficant

gs_lm2 <- update(gs_lm, .~. +sqrt(mean_linear_intercept)) #no good

gs_lm3 <- update(gs_lm, .~. + s +pct_dark_phase) #no good, mn doesn't change
summary(gs_lm3)

gs_lm4 <- update(gs_lm, .~. + c) # good, carbon p-value =.02 

glance(gs_lm3)
glance(gs_lm4)

summary(gs_lm4)


gs_aug <- augment(gs_lm4, complete)

library(rstanarm)
options(mc.cores = parallel::detectCores())

stan_gs <- stan_glm(CVN_US_FS ~ ags + pdp, data = cvn_bake)
stan_gs2 <- stan_glm(CVN_US_FS ~ pdp + c, data = cvn_bake)
stan_gs3 <- stan_glm(CVN_US_FS ~ ags + c, data = cvn_bake)
stan_gs4 <- stan_glm(CVN_US_FS ~ ags:pdp + pdp, data = cvn_bake)
stan_gs5 <- stan_glm(CVN_US_FS ~ ags:pdp + pdp + si, data = cvn_bake)

print(stan_gs)
print(stan_gs2)
print(stan_gs3)
print(stan_gs4)
print(stan_gs5)
summary(stan_gs4)

plot(stan_gs, plotfun = "areas", prob=0.95,pars = "pdp")+
  labs(title = "Uncertainty for Carbon Coefficient")

bayesplot::mcmc_areas_ridges(stan_gs)+labs(title = "Main Title")


```


```{r}
.fitted <- predict(stan_gs4,newdata = cvn_bake)

stan_aug <- bind_cols(cvn_bake, .fitted =.fitted)

stan_aug %>% 
  ggplot(aes(.fitted, CVN_US_FS))+
  geom_point(col='orangered')+
  geom_abline(lty=2, col='grey50')+
  coord_obs_pred()+
  labs(title = "Observed CVN vs. Predicted",
       x="Predicted CVN (ft-lb)",
       y = "Full-Size US CVN (ft-lb)",
       caption = "Model: CVN ~ DP + AGS:DP")
```


```{r interaction plot}
complete %>% 
  pivot_longer(-CVN_US_FS) %>% 
  ggplot(aes(value, CVN_US_FS))+
  geom_point(aes(col=name), show.legend = F)+
  facet_wrap( ~ name, scales = "free_x")+
  geom_smooth(method = "lm", se=F)

```


```{r plot_grain_size}
gs_aug %>% 
   ggplot(aes(.fitted,CVN_US_FS))+
  geom_point(col='orangered')+
  geom_abline(lty=2, col='grey50')+
  coord_obs_pred()+
  annotate("text", x= 75, y = 250,label=expression(R^2 ~ "= 0.57"), size=5)+
  labs(title = "Observed CVN vs. Predicted",
       caption = "Model: CVN ~ ASTM_GS + C",
       x="Predicted")

```

